from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from dotenv import load_dotenv

load_dotenv()

# åˆå§‹åŒ– LLM
llm = ChatOpenAI(model="gpt-4.1-nano", temperature=0)

# æ¨¡æ‹Ÿå¤šè½®å¯¹è¯çš„å†å²è®°å½•
messages = []

# å®šä¹‰ä¸‰ä¸ªè¿ç»­çš„é—®é¢˜
questions = [
    "ä½ å¥½ï¼Œè¯·é—®ä½ æ˜¯è°ï¼Ÿ",
    "ç»™æˆ‘è®²ä¸€ä¸ªå…³äºç¨‹åºå‘˜çš„å†·ç¬‘è¯ã€‚",
    "åˆšæ‰é‚£ä¸ªç¬‘è¯é‡Œçš„'ç¨‹åºå‘˜'å¦‚æœæ¢æˆ'AI'ï¼Œç¬‘ç‚¹åœ¨å“ªé‡Œï¼Ÿ"
]

"""
å…³äºå¤šè½®å¯¹è¯çš„æœ¬è´¨ï¼š

1. API æ˜¯æ— çŠ¶æ€çš„ (Stateless)ï¼š
   - æ¨¡å‹ä¸è®°å¾—ä¸Šä¸€è½®çš„å¯¹è¯å†…å®¹ã€‚
   - æ¯æ¬¡è°ƒç”¨ llm.invoke() éƒ½æ˜¯ä¸€æ¬¡å…¨æ–°çš„ç‹¬ç«‹è¯·æ±‚ã€‚

2. ä¸Šä¸‹æ–‡é å®¢æˆ·ç«¯ç»´æŠ¤ï¼š
   - æ‰€è°“çš„"å¤šè½®å¯¹è¯"ï¼Œæœ¬è´¨ä¸Šæ˜¯å®¢æˆ·ç«¯å°†"å†å²è®°å½• + æœ€æ–°é—®é¢˜"æ‰“åŒ…ä¸€èµ·å‘é€ç»™æ¨¡å‹ã€‚
   - å³ç”¨æˆ·è‡ªå·±ç»´æŠ¤ä¸€ä¸ª messages åˆ—è¡¨ï¼Œæ¯æ¬¡è°ƒç”¨ llm.invoke() æ—¶ï¼Œå°† messages åˆ—è¡¨ä½œä¸ºå‚æ•°ä¼ å…¥ã€‚
   - æ¨¡å‹é€šè¿‡é˜…è¯»å®Œæ•´çš„å†å²è®°å½•ï¼Œ"å‡è£…"æ‹¥æœ‰è®°å¿†å¹¶ç”Ÿæˆè¿è´¯çš„å›ç­”ã€‚

3. å¸¦æ¥çš„æŒ‘æˆ˜ï¼š
   - Token æ¶ˆè€—ï¼šéšç€å¯¹è¯å˜é•¿ï¼Œé‡å¤å‘é€çš„å†å²å†…å®¹è¶Šæ¥è¶Šå¤šï¼Œæˆæœ¬å’Œå»¶è¿Ÿå¢åŠ ã€‚
   - çª—å£é™åˆ¶ï¼šå—é™äºæ¨¡å‹çš„ Context Window (å¦‚ 128k)ï¼Œæ— æ³•æ— é™å­˜å‚¨ï¼Œéœ€è¦è¿›è¡Œè®°å¿†ç®¡ç†(æ€»ç»“/æˆªæ–­)ã€‚
"""

print("=== å¼€å§‹å¤šè½®å¯¹è¯æµ‹è¯• ===\n")

for i, question in enumerate(questions, 1):
    print(f"--- Round {i} ---")
    print(f"ğŸ‘¤ User: {question}")
    
    # 1. å°†ç”¨æˆ·é—®é¢˜åŠ å…¥å†å²
    messages.append(HumanMessage(content=question))
    
    # 2. è°ƒç”¨ LLM (ä¼ å…¥å®Œæ•´å†å²)
    response = llm.invoke(messages)
    
    # 3. æ‰“å°å›ç­”
    print(f"ğŸ¤– AI:   {response.content}\n")
    
    # 4. å°† AI å›ç­”åŠ å…¥å†å²ï¼Œä»¥ä¾¿ä¸‹ä¸€è½®èƒ½è®°ä½ä¸Šä¸‹æ–‡
    messages.append(response)

print("=== å¯¹è¯ç»“æŸ ===")
print(messages)
