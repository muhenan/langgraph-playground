# /// script
# dependencies = [
#     "langgraph",
#     "langchain-openai",
#     "langchain-core",
#     "python-dotenv"
# ]
# ///

import operator
from typing import TypedDict, Annotated, List, Literal, Union
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from pydantic import BaseModel, Field

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver

from utils.visualizer import visualize_graph

load_dotenv()

# ==========================================
# 1. State Definitions
# ==========================================

# æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå­—æ®µæ¥å­˜å‚¨"ä¸‹ä¸€ä¸ªæ˜¯è°"
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages] # ä¸€é•¿ä¸²èŠå¤©è®°å½• Chat æ¨¡å¼
    next: str

# ==========================================
# 2. The Supervisor (The Brain)
# ==========================================
llm_supervisor = ChatOpenAI(model="gpt-4.1-nano", temperature=0)

# å®šä¹‰ Supervisor çš„å¯é€‰è¾“å‡º
# è¿™å°±æ˜¯"è·¯ç”±è¡¨"ï¼ŒLLM å¿…é¡»ä»ä¸­é€‰ä¸€ä¸ª
members = ["Coder", "Reviewer"]
options = ["FINISH"] + members

# ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºå¼ºåˆ¶ LLM åšé€‰æ‹©
class RouteResponse(BaseModel):
    next: Literal["FINISH", "Coder", "Reviewer"] = Field(
        description="Who should act next? Select 'FINISH' if the task is complete."
    )

def supervisor_node(state: AgentState):
    """
    ä¸»ç®¡èŠ‚ç‚¹ï¼šåªè´Ÿè´£è§‚å¯Ÿå†å²ï¼Œå†³å®šä¸‹ä¸€æ­¥å»å“ªé‡Œã€‚
    """
    print("--- [Supervisor] Thinking... ---")
    
    system_prompt = (
        "You are a supervisor managing a conversation between the following workers: "
        f"{members}. Given the following user request, respond with the worker to act next. "
        "Each worker will perform a task and respond with their results and status. "
        "When finished, respond with FINISH."
    )
    
    # æ„é€  Promptï¼ŒåŒ…å«å®Œæ•´çš„å†å²è®°å½•
    messages = [SystemMessage(content=system_prompt)] + state["messages"]
    
    # ä½¿ç”¨ with_structured_output å¼ºåˆ¶è¾“å‡º JSON
    structured_llm = llm_supervisor.with_structured_output(RouteResponse)
    response = structured_llm.invoke(messages)
    
    next_agent = response.next
    print(f"--- [Supervisor] Route -> {next_agent} ---")
    
    # æˆ‘ä»¬ä¸å¾€ messages é‡Œå†™ Supervisor çš„å†³ç­–è¿‡ç¨‹ï¼Œåªæ›´æ–° 'next' å­—æ®µ
    # è¿™æ ·å¯¹è¯å†å²çœ‹èµ·æ¥å°±åƒæ˜¯ Coder å’Œ Reviewer åœ¨ç›´æ¥å¯¹è¯
    return {"next": next_agent}

# ==========================================
# 3. The Workers (Coder & Reviewer)
# ==========================================
llm_worker = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)

def coder_node(state: AgentState):
    """å†™ä»£ç çš„å·¥äºº"""
    print("  -> [Coder] Working...")
    
    messages = [
        SystemMessage(content=(
            "You are a Python Coder. "
            "Write code to solve the user's problem. "
            "Return the code in a markdown block (```python ... ```). "
            # [æ ¸å¿ƒä¿®æ”¹]: æ˜ç¡®ç¦æ­¢å®ƒåš Review
            "IMPORTANT: Do NOT review the code yourself. Do NOT explain the code. "
            "Just output the code block. Another agent will review it."
        )),
    ] + state["messages"]
    
    response = llm_worker.invoke(messages)
    
    # åŠ ä¸Šå‰ç¼€æ–¹ä¾¿å®¡è®¡
    return {
        "messages": [AIMessage(content=f"[Coder]: {response.content}")]
    }

def reviewer_node(state: AgentState):
    """å®¡æŸ¥ä»£ç çš„å·¥äºº"""
    print("  -> [Reviewer] Reviewing...")
    
    messages = [
        SystemMessage(content="You are a Code Reviewer. Check the Coder's code. If it looks good, say 'LGTM'. If not, ask for changes."),
    ] + state["messages"]
    
    response = llm_worker.invoke(messages)
    
    return {
        "messages": [AIMessage(content=f"[Reviewer]: {response.content}")]
    }

# ==========================================
# 4. Graph Construction
# ==========================================
def main():
    builder = StateGraph(AgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    builder.add_node("supervisor", supervisor_node)
    builder.add_node("Coder", coder_node)
    builder.add_node("Reviewer", reviewer_node)
    
    # [å…³é”®è¾¹]: æ‰€æœ‰å·¥äººåœ¨å®Œæˆå·¥ä½œåï¼Œå¿…é¡»æ±‡æŠ¥ç»™ Supervisor
    builder.add_edge("Coder", "supervisor")
    builder.add_edge("Reviewer", "supervisor")
    
    # [å…¥å£]: ä¹Ÿæ˜¯å…ˆæ‰¾ Supervisor
    builder.add_edge(START, "supervisor")
    
    # [æ¡ä»¶è¾¹]: Supervisor å†³å®šå»å“ªé‡Œ
    # è¿™æ˜¯ä¸€ä¸ªåŠ¨æ€è·¯ç”±é€»è¾‘
    builder.add_conditional_edges(
        "supervisor",
        lambda state: state["next"], # è¯»å– state["next"]
        {
            "Coder": "Coder",
            "Reviewer": "Reviewer",
            "FINISH": END
        }
    )
    
    graph = builder.compile(checkpointer=MemorySaver())
    visualize_graph(graph, "08_supervisor.png")

    # ==========================================
    # 5. Execution & Audit
    # ==========================================
    config = {"configurable": {"thread_id": "team_coding"}}
    
    # è¿™é‡Œæˆ‘ä»¬æ•…æ„ç»™ä¸€ä¸ªç¨å¾®å¤æ‚çš„ä»»åŠ¡ï¼Œè®©å®ƒä»¬äº’åŠ¨èµ·æ¥
    user_query = "Write a Python script to calculate Fibonacci sequence, then review it."
    print(f"User Request: {user_query}")
    
    # è¿è¡Œå›¾
    # event çš„æ ¼å¼é€šå¸¸æ˜¯: {'node_name': {'key': 'value'}}
    for event in graph.stream(
        {"messages": [HumanMessage(content=user_query)]}, 
        config=config, 
        recursion_limit=20
    ):
        for node_name, state_update in event.items():
            # 1. æ•è· Supervisor çš„å†³ç­–
            if node_name == "supervisor":
                next_step = state_update.get("next")
                print(f"ğŸ‘€ [Supervisor] Routing to -> {next_step}")
            
            # 2. æ•è· Coder æˆ– Reviewer çš„è¾“å‡º
            elif node_name in ["Coder", "Reviewer"]:
                # è·å–è¯¥èŠ‚ç‚¹ç”Ÿæˆçš„æœ€æ–°ä¸€æ¡æ¶ˆæ¯
                messages = state_update.get("messages", [])
                if messages:
                    last_msg = messages[-1]
                    # ä¸ºäº†æ§åˆ¶å°æ•´æ´ï¼Œæˆ‘ä»¬å°†æ¢è¡Œç¬¦æ›¿æ¢ä¸ºç©ºæ ¼ï¼Œå¹¶æˆªæ–­è¿‡é•¿çš„å†…å®¹
                    content_preview = last_msg.content.replace("\n", " ")
                    if len(content_preview) > 100:
                        content_preview = content_preview[:100] + "..."
                    
                    icon = "ğŸ’»" if node_name == "Coder" else "ğŸ”"
                    print(f"{icon}  [{node_name}] Output: {content_preview}")
        
    print_audit_log(graph, config)

def print_audit_log(graph, config):
    print("\n" + "="*60)
    print("ğŸ“œ  FULL CONVERSATION HISTORY (AUDIT LOG)")
    print("="*60)
    final_snapshot = graph.get_state(config)
    for msg in final_snapshot.values.get("messages", []):
        icon = "ğŸ‘¤"
        role = "User"
        if isinstance(msg, AIMessage):
            if "[Coder]" in msg.content:
                icon = "ğŸ’»"
                role = "Coder"
                msg.content = msg.content.replace("[Coder]: ", "")
            elif "[Reviewer]" in msg.content:
                icon = "ğŸ”"
                role = "Reviewer"
                msg.content = msg.content.replace("[Reviewer]: ", "")
            else:
                icon = "ğŸ¤–"
                role = "AI"
        
        print(f"{icon} [{role}]: {msg.content[:500]}...") # åªæ‰“å°å‰500å­—é¿å…åˆ·å±
        print("-" * 60)

if __name__ == "__main__":
    main()